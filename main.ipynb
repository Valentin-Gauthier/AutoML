{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b08e001a-3775-42f5-ad1a-76cb0e33628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load dataset] Loading Dense dataset: data\n",
      "[fit] binary_classification task detected.\n",
      "\n",
      "    Dataset Target Analysis (5418 samples)\n",
      " Type: Binary Classification [Balanced]\n",
      "  -> Class 0  : 2709   samples (50.00%)\n",
      "  -> Class 1  : 2709   samples (50.00%)\n",
      "\n",
      "\n",
      "[fit] Features threshold exceeded (1636 > 800).\n",
      "[fit] Reducing to the top 800 features...\n",
      "[fit] Warning: Only kept 48.90% of the features !\n",
      "[fit] Reduction done. New shape: (4334, 800)\n",
      "\n",
      "[fit] Candidate models loaded for task 'binary_classification':\n",
      "   1. Logistic Regression\n",
      "   2. Hist Gradient Boosting\n",
      "   3. K-Neighbors Classifier\n",
      "   4. Gaussian Naive Bayes\n",
      "   5. SVC\n",
      "   6. Random Forest Classifier\n",
      "   7. Bernoulli Naive Bayes\n",
      "   8. Gradient Boosting Classifier\n",
      "   9. MLP Classifier\n",
      "   10. Linear SVC\n",
      "   11. Extra Trees Classifier\n",
      "\n",
      " [filter models] Dynamic Model Filtering ---\n",
      " Dataset Info: 4334 rows, 800 cols, Sparse=False\n",
      " [EXCLUDED] K-Neighbors Classifier............. : Ineffective in high dimensions (800 cols)\n",
      " [EXCLUDED] Gaussian Naive Bayes............... : Incompatible with negative values (StandardScaler)\n",
      " [EXCLUDED] SVC................................ : Too slow for matrix 4334x800\n",
      " [EXCLUDED] Bernoulli Naive Bayes.............. : Incompatible with negative values (StandardScaler)\n",
      " -> Models selected: 7 / 11\n",
      "\n",
      "[CLUSTER] Optimizing: Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/info/etu/m1/s2501728/miniconda3/envs/autoML_env/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:110: UserWarning: Features [  72  155  213  244  256  261  477  545  574  583  646  687  832  856\n",
      "  934 1004 1009 1186 1228 1238 1239 1255 1259 1355 1486 1585] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/info/etu/m1/s2501728/miniconda3/envs/autoML_env/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLUSTER] Success (272.1s). Best params: {'C': 0.013413441515429125, 'solver': 'lbfgs', 'max_iter': 2000}\n",
      "[fit] Retraining final model on full data...\n",
      "[fit] Final training done in 0.2s.\n",
      "[CLUSTER] Optimizing: Hist Gradient Boosting...\n",
      "[CLUSTER] Success (1259.2s). Best params: {'learning_rate': 0.05126093383525258, 'max_iter': 443, 'max_depth': 20, 'l2_regularization': 0.5781645319628474, 'early_stopping': True, 'n_iter_no_change': 10}\n",
      "[fit] Retraining final model on full data...\n",
      "[fit] Final training done in 5.2s.\n",
      "[CLUSTER] Optimizing: Random Forest Classifier...\n",
      "[CLUSTER] Success (371.0s). Best params: {'n_estimators': 99, 'max_depth': 30, 'min_samples_split': 9, 'min_samples_leaf': 3, 'class_weight': None, 'n_jobs': 1}\n",
      "[fit] Retraining final model on full data...\n",
      "[fit] Final training done in 5.5s.\n",
      "[CLUSTER] Optimizing: Gradient Boosting Classifier...\n",
      "[CLUSTER] Success (2463.8s). Best params: {'n_estimators': 161, 'learning_rate': 0.05211537484182655, 'max_depth': 6, 'subsample': 0.8388354230229181, 'n_iter_no_change': 10, 'validation_fraction': 0.1}\n",
      "[fit] Retraining final model on full data...\n",
      "[fit] Final training done in 97.5s.\n",
      "[CLUSTER] Optimizing: MLP Classifier...\n",
      "[CLUSTER] Success (162.2s). Best params: {'hidden_layer_sizes': [100], 'activation': 'relu', 'alpha': 0.0005206710037630879, 'learning_rate_init': 0.0011996748486212269, 'max_iter': 500, 'early_stopping': True, 'n_iter_no_change': 10}\n",
      "[fit] Retraining final model on full data...\n",
      "[fit] Final training done in 0.7s.\n",
      "[CLUSTER] Optimizing: Linear SVC...\n",
      "[CLUSTER] Error optimizing Linear SVC: Job 255292 (task: 0) with path /info/etu/m1/s2501728/AutoML/automl_logs/255292_0_result.pkl\n",
      "has not produced any output (state: TIMEOUT)\n",
      "Error stream produced:\n",
      "----------------------------------------\n",
      "srun: Job step aborted: Waiting up to 2 seconds for job step to finish.\n",
      "slurmstepd-gpue12: error: *** STEP 255292.0 ON gpue12 CANCELLED AT 2026-01-11T18:53:03 DUE TO TIME LIMIT ***\n",
      "slurmstepd-gpue12: error: *** JOB 255292 ON gpue12 CANCELLED AT 2026-01-11T18:53:03 DUE TO TIME LIMIT ***\n",
      "\n",
      "[LOCAL] Fallback: Training locally with default params.\n",
      "[CLUSTER] Optimizing: Extra Trees Classifier...\n",
      "[CLUSTER] Success (136.6s). Best params: {'n_estimators': 177, 'max_depth': 20, 'min_samples_split': 8, 'n_jobs': 1}\n",
      "[fit] Retraining final model on full data...\n",
      "[fit] Final training done in 2.4s.\n",
      "\n",
      "[eval] --- Detailed Results on Test Set (1084 samples) ---\n",
      "\n",
      " > Model: Logistic Regression\n",
      "   - Accuracy : 0.7260\n",
      "   - F1 Macro : 0.7259 (Balanced metric)\n",
      "\n",
      "[Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.73      0.73       554\n",
      "         1.0       0.72      0.72      0.72       530\n",
      "\n",
      "    accuracy                           0.73      1084\n",
      "   macro avg       0.73      0.73      0.73      1084\n",
      "weighted avg       0.73      0.73      0.73      1084\n",
      "\n",
      "\n",
      " > Model: Hist Gradient Boosting\n",
      "   - Accuracy : 0.7297\n",
      "   - F1 Macro : 0.7296 (Balanced metric)\n",
      "\n",
      "[Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.73      0.73       554\n",
      "         1.0       0.72      0.73      0.73       530\n",
      "\n",
      "    accuracy                           0.73      1084\n",
      "   macro avg       0.73      0.73      0.73      1084\n",
      "weighted avg       0.73      0.73      0.73      1084\n",
      "\n",
      "\n",
      " > Model: Random Forest Classifier\n",
      "   - Accuracy : 0.7251\n",
      "   - F1 Macro : 0.7246 (Balanced metric)\n",
      "\n",
      "[Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.75      0.74       554\n",
      "         1.0       0.73      0.70      0.71       530\n",
      "\n",
      "    accuracy                           0.73      1084\n",
      "   macro avg       0.73      0.72      0.72      1084\n",
      "weighted avg       0.73      0.73      0.72      1084\n",
      "\n",
      "\n",
      " > Model: Gradient Boosting Classifier\n",
      "   - Accuracy : 0.7306\n",
      "   - F1 Macro : 0.7302 (Balanced metric)\n",
      "\n",
      "[Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.75      0.74       554\n",
      "         1.0       0.73      0.71      0.72       530\n",
      "\n",
      "    accuracy                           0.73      1084\n",
      "   macro avg       0.73      0.73      0.73      1084\n",
      "weighted avg       0.73      0.73      0.73      1084\n",
      "\n",
      "\n",
      " > Model: MLP Classifier\n",
      "   - Accuracy : 0.7343\n",
      "   - F1 Macro : 0.7343 (Balanced metric)\n",
      "\n",
      "[Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.74      0.73      0.74       554\n",
      "         1.0       0.72      0.74      0.73       530\n",
      "\n",
      "    accuracy                           0.73      1084\n",
      "   macro avg       0.73      0.73      0.73      1084\n",
      "weighted avg       0.73      0.73      0.73      1084\n",
      "\n",
      "\n",
      " > Model: Linear SVC\n",
      "   - Accuracy : 0.7131\n",
      "   - F1 Macro : 0.7130 (Balanced metric)\n",
      "\n",
      "[Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.72      0.72       554\n",
      "         1.0       0.71      0.71      0.71       530\n",
      "\n",
      "    accuracy                           0.71      1084\n",
      "   macro avg       0.71      0.71      0.71      1084\n",
      "weighted avg       0.71      0.71      0.71      1084\n",
      "\n",
      "\n",
      " > Model: Extra Trees Classifier\n",
      "   - Accuracy : 0.7334\n",
      "   - F1 Macro : 0.7329 (Balanced metric)\n",
      "\n",
      "[Classification Report]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.76      0.74       554\n",
      "         1.0       0.74      0.71      0.72       530\n",
      "\n",
      "    accuracy                           0.73      1084\n",
      "   macro avg       0.73      0.73      0.73      1084\n",
      "weighted avg       0.73      0.73      0.73      1084\n",
      "\n",
      "\n",
      "==================================================\n",
      " BEST MODEL : MLP Classifier\n",
      " Score      : 0.7343\n",
      " Params     : {'hidden_layer_sizes': [100], 'activation': 'relu', 'alpha': 0.0005206710037630879, 'learning_rate_init': 0.0011996748486212269, 'max_iter': 500, 'early_stopping': True, 'n_iter_no_change': 10}\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from src.nevergrad import automl\n",
    "importlib.reload(automl)\n",
    "from src.nevergrad.automl import AutoML\n",
    "\n",
    "automl = AutoML(                   \n",
    "    verbose=True\n",
    ")\n",
    "data_dest_traindev=\"/info/corpus/ChallengeMachineLearning/data_test/data.data\"\n",
    "automl.fit(data_dest_traindev)\n",
    "automl.eval()  # Renvoie des résultats d'évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad59a16-5370-4f31-9890-1c0961a2932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[predict] Loading data from /info/corpus/ChallengeMachineLearning/data_A...\n",
      "[load dataset] Loading Dense dataset: data_A\n",
      "[predict] Predicting using GradientBoostingClassifier (wrapped in MultiOutputClassifier)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_testset = \"/info/corpus/ChallengeMachineLearning/data_test/data_test.data\"\n",
    "automl.predict(path_to_testset) #retourne une liste avec les predictions par donnée du dataset (donc par ligne de donnée)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (autoML_env)",
   "language": "python",
   "name": "automl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
