############################################### Traitement du dataset : data_H #############################################
[load dataset] Loading Sparse dataset: data_H
[fit] multilabel_classification task detected.

    Dataset Target Analysis (45400 samples)
   Type: Multi-label (91 labels)
 - Average labels per sample: 1.43
 -> Label 72 : 5353   (11.79%)
 -> Label 52 : 5183   (11.42%)
 -> Label 23 : 2862   (6.30%)
 -> Label 76 : 2803   (6.17%)
 -> Label 6  : 2338   (5.15%)
 -> Label 1  : 2223   (4.90%)
 -> Label 65 : 2199   (4.84%)
 -> Label 70 : 2134   (4.70%)
 -> Label 43 : 2068   (4.56%)
 -> Label 86 : 1741   (3.83%)
 -> Label 36 : 1703   (3.75%)
 -> Label 46 : 1479   (3.26%)
 -> Label 20 : 1438   (3.17%)
 -> Label 22 : 1363   (3.00%)
 -> Label 62 : 1289   (2.84%)
 -> Label 54 : 1163   (2.56%)
 -> Label 48 : 1133   (2.50%)
 -> Label 67 : 1102   (2.43%)
 -> Label 3  : 1082   (2.38%)
 -> Label 30 : 1041   (2.29%)
 -> Label 33 : 977    (2.15%)
 -> Label 59 : 847    (1.87%)
 -> Label 64 : 845    (1.86%)
 -> Label 18 : 807    (1.78%)
 -> Label 8  : 778    (1.71%)
 -> Label 19 : 757    (1.67%)
 -> Label 63 : 636    (1.40%)
 -> Label 24 : 618    (1.36%)
 -> Label 60 : 617    (1.36%)
 -> Label 39 : 612    (1.35%)
 -> Label 7  : 611    (1.35%)
 -> Label 29 : 608    (1.34%)
 -> Label 42 : 603    (1.33%)
 -> Label 27 : 554    (1.22%)
 -> Label 11 : 548    (1.21%)
 -> Label 75 : 521    (1.15%)
 -> Label 71 : 521    (1.15%)
 -> Label 49 : 514    (1.13%)
 -> Label 80 : 502    (1.11%)
 -> Label 21 : 500    (1.10%)
 -> Label 17 : 464    (1.02%)
 -> Label 84 : 452    (1.00%)
 -> Label 9  : 434    (0.96%)
 -> Label 50 : 422    (0.93%)
 -> Label 73 : 398    (0.88%)
 -> Label 57 : 378    (0.83%)
 -> Label 45 : 359    (0.79%)
 -> Label 16 : 317    (0.70%)
 -> Label 68 : 317    (0.70%)
 -> Label 66 : 302    (0.67%)
 -> Label 26 : 287    (0.63%)
 -> Label 88 : 250    (0.55%)
 -> Label 2  : 250    (0.55%)
 -> Label 5  : 246    (0.54%)
 -> Label 89 : 246    (0.54%)
 -> Label 0  : 242    (0.53%)
 -> Label 4  : 237    (0.52%)
 -> Label 58 : 225    (0.50%)
 -> Label 79 : 217    (0.48%)
 -> Label 55 : 204    (0.45%)
 -> Label 38 : 203    (0.45%)
 -> Label 37 : 202    (0.44%)
 -> Label 61 : 201    (0.44%)
 -> Label 44 : 200    (0.44%)
 -> Label 74 : 195    (0.43%)
 -> Label 28 : 190    (0.42%)
 -> Label 47 : 178    (0.39%)
 -> Label 82 : 164    (0.36%)
 -> Label 87 : 161    (0.35%)
 -> Label 10 : 161    (0.35%)
 -> Label 78 : 157    (0.35%)
 -> Label 34 : 156    (0.34%)
 -> Label 15 : 146    (0.32%)
 -> Label 51 : 129    (0.28%)
 -> Label 14 : 127    (0.28%)
 -> Label 83 : 125    (0.28%)
 -> Label 77 : 124    (0.27%)
 -> Label 13 : 118    (0.26%)
 -> Label 90 : 118    (0.26%)
 -> Label 31 : 112    (0.25%)
 -> Label 85 : 109    (0.24%)
 -> Label 32 : 107    (0.24%)
 -> Label 56 : 104    (0.23%)
 -> Label 40 : 104    (0.23%)
 -> Label 53 : 99     (0.22%)
 -> Label 25 : 87     (0.19%)
 -> Label 12 : 85     (0.19%)
 -> Label 41 : 82     (0.18%)
 -> Label 69 : 73     (0.16%)
 -> Label 35 : 73     (0.16%)
 -> Label 81 : 49     (0.11%)



[fit] Candidate models loaded for task 'multilabel_classification':
   1. Random Forest Classifier Multi-label
   2. K-Neighbors Classifier Multi-label
   3. Gradient Boosting Classifier Multi-label
   4. Hist Gradient Boosting Multi-label
   5. MLP Multi-label
   6. Ridge Classifier

 [filter models] Dynamic Model Filtering ---
 Dataset Info: 36320 rows, 301562 cols, Sparse=True
 Target Info : 91 labels (Multi-label)
 [EXCLUDED] K-Neighbors Classifier Multi-label. : Ineffective in high dimensions (301562 cols)
 [EXCLUDED] Gradient Boosting Classifier Multi-label : Too heavy for 91 labels (requires 91 models)
 [EXCLUDED] Hist Gradient Boosting Multi-label. : Incompatible with Sparse data
 -> Models selected: 3 / 6

[CLUSTER] Optimizing: Random Forest Classifier Multi-label...
