# ==========================================================
# CONFIGURATION NEVERGRAD
# ==========================================================

# ----------------------------------------------------------
# 1. REGRESSION
# ----------------------------------------------------------

Linear Regression:
  fit_intercept: [True, False]

Ridge:
  alpha: 
    type: log
    min: 0.01
    max: 100.0

K-Neighbors Regressor:
  n_neighbors: 
    type: int
    min: 3
    max: 30
  weights: ['distance', 'uniform']
  p: [1, 2] # 1=Manhattan, 2=Euclidean
  n_jobs: 1

SVR:
  C: 
    type: log
    min: 0.1
    max: 1000.0
  kernel: ['rbf', 'linear'] 
  gamma: ['scale', 'auto', 0.1, 0.01]
  epsilon: 
    type: float
    min: 0.01
    max: 0.5
  max_iter: 20000

Random Forest Regressor:
  n_estimators: 
    type: int
    min: 50
    max: 500
  max_depth: [10, 20, 30, 50, 80, null]
  min_samples_split: 
    type: int
    min: 2
    max: 15
  min_samples_leaf: 
    type: int
    min: 1
    max: 4
  n_jobs: 1

Gradient Boosting Regressor:
  n_estimators: 
    type: int
    min: 100
    max: 500
  learning_rate: 
    type: log
    min: 0.01
    max: 0.2
  max_depth: 
    type: int
    min: 3
    max: 8
  subsample: 
    type: float
    min: 0.8
    max: 1.0

# Attention: encapsulé dans TransformedTargetRegressor -> préfixe 'regressor__'
MLP Regressor:
  regressor__hidden_layer_sizes: [[50], [100], [100, 50], [100, 100], [200, 100]]
  regressor__activation: ['relu', 'tanh']
  regressor__alpha: 
    type: log
    min: 0.00001
    max: 0.01
  regressor__learning_rate_init: 
    type: log
    min: 0.001
    max: 0.01
  regressor__max_iter: 1000

Hist Gradient Boosting:
  learning_rate: 
    type: log
    min: 0.01
    max: 0.2
  max_iter: 
    type: int
    min: 100
    max: 1000
  max_depth: [null, 10, 20, 50]
  l2_regularization: 
    type: float
    min: 0.0
    max: 1.0

# ----------------------------------------------------------
# 2. BINARY & MULTICLASS CLASSIFICATION
# ----------------------------------------------------------

Logistic Regression:
  C: 
    type: log
    min: 0.01
    max: 100.0
  solver: ['lbfgs']
  max_iter: 5000

K-Neighbors Classifier:
  n_neighbors: 
    type: int
    min: 3
    max: 20
  weights: ['distance', 'uniform']
  p: [1, 2]
  n_jobs: 1

Gaussian Naive Bayes:
  var_smoothing: 
    type: log
    min: 0.0000000001
    max: 0.00001

Bernoulli Naive Bayes:
  alpha: 
    type: log
    min: 0.01
    max: 2.0
  binarize: 
    type: float
    min: 0.0
    max: 0.7

SVC:
  C: 
    type: log
    min: 0.1
    max: 1000.0
  kernel: ['rbf', 'poly', 'sigmoid']
  gamma: ['scale', 'auto']
  probability: True # Requis par ta config Python
  max_iter: 10000

Random Forest Classifier:
  n_estimators: 
    type: int
    min: 50
    max: 500
  max_depth: [10, 20, 30, 50, null]
  min_samples_split: 
    type: int
    min: 2
    max: 10
  min_samples_leaf: 
    type: int
    min: 1
    max: 4
  class_weight: [null, 'balanced']
  n_jobs: 1

Gradient Boosting Classifier:
  n_estimators: 
    type: int
    min: 100
    max: 500
  learning_rate: 
    type: log
    min: 0.01
    max: 0.3
  max_depth: 
    type: int
    min: 3
    max: 8
  subsample: 
    type: float
    min: 0.8
    max: 1.0

MLP Classifier:
  hidden_layer_sizes: [[50], [100], [100, 50], [100, 100], [200, 100]]
  activation: ['relu', 'tanh']
  alpha: 
    type: log
    min: 0.00001
    max: 0.01
  learning_rate_init: 
    type: log
    min: 0.001
    max: 0.01
  max_iter: 1000

# ----------------------------------------------------------
# 3. MULTI-LABEL CLASSIFICATION
# Note: Préfixe 'estimator__' requis car MultiOutputClassifier
# ----------------------------------------------------------

Random Forest Classifier Multi-label:
  estimator__n_estimators: 
    type: int
    min: 50
    max: 500
  estimator__max_depth: [10, 20, 40, 60, 100, null]
  estimator__min_samples_leaf: 
    type: int
    min: 1
    max: 4
  estimator__n_jobs: 1

K-Neighbors Classifier Multi-label:
  estimator__n_neighbors: 
    type: int
    min: 3
    max: 15
  estimator__weights: ['distance', 'uniform']
  estimator__n_jobs: 1

Gradient Boosting Classifier Multi-label:
  estimator__n_estimators: 
    type: int
    min: 500
    max: 1000  
  estimator__learning_rate: 
    type: log
    min: 0.005
    max: 0.05
  estimator__max_depth: 
    type: int
    min: 3
    max: 9
  estimator__subsample: 
    type: float
    min: 0.7
    max: 0.95

Hist Gradient Boosting Multi-label:
  estimator__learning_rate: 
    type: log
    min: 0.01
    max: 0.2
  estimator__max_iter: 
    type: int
    min: 100
    max: 1000
  estimator__max_depth: [null, 10, 20, 50]
  estimator__l2_regularization: 
    type: float
    min: 0.0
    max: 1.0

# MLP Multi-label est NATIF (pas de wrapper), donc PAS de préfixe estimator__
MLP Multi-label:
  hidden_layer_sizes: [[100], [100, 50],[200, 100], [300, 150], [50, 50, 50]]
  activation: ['relu', 'tanh']
  alpha: 
    type: log
    min: 0.00001
    max: 0.01
  learning_rate_init: 
    type: log
    min: 0.001
    max: 0.01
  max_iter: 1000
  early_stopping: True
  n_iter_no_change: 10

# Ridge Classifier est dans MultiOutputClassifier -> préfixe estimator__
Ridge Classifier:
  estimator__alpha:
    type: log
    min: 0.01
    max: 100.0