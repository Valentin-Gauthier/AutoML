[load dataset] Loading Dense dataset: data_G
[fit] binary_classification task detected.

    Dataset Target Analysis (5124 samples)
 Type: Binary Classification [Balanced]
  -> Class 0  : 2562   samples (50.00%)
  -> Class 1  : 2562   samples (50.00%)



[fit] Candidate models loaded for task 'binary_classification':
   1. Logistic Regression
   2. Hist Gradient Boosting
   3. K-Neighbors Classifier
   4. Gaussian Naive Bayes
   5. SVC
   6. Random Forest Classifier
   7. Bernoulli Naive Bayes
   8. Gradient Boosting Classifier
   9. MLP Classifier
   10. Linear SVC
   11. Extra Trees Classifier

 [filter models] Dynamic Model Filtering ---
 Dataset Info: 4099 rows, 20 cols, Sparse=False
 [EXCLUDED] Gaussian Naive Bayes............... : Incompatible with negative values (StandardScaler)
 [EXCLUDED] Bernoulli Naive Bayes.............. : Incompatible with negative values (StandardScaler)
 -> Models selected: 9 / 11

[CLUSTER] Optimizing: Logistic Regression...
[CLUSTER] Success (25.4s). Best params: {'C': 0.4114690359768339, 'solver': 'lbfgs', 'max_iter': 2000}
[fit] Retraining final model on full data...
[fit] Final training done in 2.3s.
[CLUSTER] Optimizing: Hist Gradient Boosting...
[CLUSTER] Success (72.4s). Best params: {'learning_rate': 0.16034820509315073, 'max_iter': 144, 'max_depth': 10, 'l2_regularization': 0.1355780450946784, 'early_stopping': True, 'n_iter_no_change': 10}
[fit] Retraining final model on full data...
[fit] Final training done in 0.6s.
[CLUSTER] Optimizing: K-Neighbors Classifier...
[CLUSTER] Success (28.9s). Best params: {'n_neighbors': 18, 'weights': 'distance', 'p': 1, 'n_jobs': 1}
[fit] Retraining final model on full data...
[fit] Final training done in 0.0s.
[CLUSTER] Optimizing: SVC...
[CLUSTER] Success (70.9s). Best params: {'C': 3.0877551137568426, 'kernel': 'rbf', 'gamma': 'scale', 'probability': True, 'max_iter': 2000}
[fit] Retraining final model on full data...
/info/etu/m1/s2501728/miniconda3/envs/autoML_env/lib/python3.12/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=2000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
[fit] Final training done in 3.6s.
[CLUSTER] Optimizing: Random Forest Classifier...
[CLUSTER] Success (69.7s). Best params: {'n_estimators': 172, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 1, 'class_weight': None, 'n_jobs': 1}
[fit] Retraining final model on full data...
[fit] Final training done in 0.9s.
[CLUSTER] Optimizing: Gradient Boosting Classifier...
[CLUSTER] Success (81.2s). Best params: {'n_estimators': 99, 'learning_rate': 0.16177700655655042, 'max_depth': 6, 'subsample': 0.8380472857922183, 'n_iter_no_change': 10, 'validation_fraction': 0.1}
[fit] Retraining final model on full data...
[fit] Final training done in 5.5s.
[CLUSTER] Optimizing: MLP Classifier...
[CLUSTER] Success (47.8s). Best params: {'hidden_layer_sizes': [100], 'activation': 'relu', 'alpha': 0.0039041147748871325, 'learning_rate_init': 0.001956226033922906, 'max_iter': 500, 'early_stopping': True, 'n_iter_no_change': 10}
[fit] Retraining final model on full data...
[fit] Final training done in 2.5s.
[CLUSTER] Optimizing: Linear SVC...
[CLUSTER] Success (26.4s). Best params: {'C': 0.010379708488865904, 'penalty': 'l2', 'max_iter': 2000}
[fit] Retraining final model on full data...
[fit] Final training done in 0.0s.
[CLUSTER] Optimizing: Extra Trees Classifier...
[CLUSTER] Success (41.4s). Best params: {'n_estimators': 150, 'max_depth': 30, 'min_samples_split': 5, 'n_jobs': 1}
[fit] Retraining final model on full data...
[fit] Final training done in 0.6s.

[eval] --- Detailed Results on Test Set (1025 samples) ---

 > Model: Logistic Regression
   - Accuracy : 0.9141
   - F1 Macro : 0.9138 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

         0.0       0.94      0.88      0.91       497
         1.0       0.89      0.95      0.92       528

    accuracy                           0.91      1025
   macro avg       0.92      0.91      0.91      1025
weighted avg       0.92      0.91      0.91      1025


 > Model: Hist Gradient Boosting
   - Accuracy : 0.9395
   - F1 Macro : 0.9392 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

         0.0       0.97      0.90      0.94       497
         1.0       0.91      0.98      0.94       528

    accuracy                           0.94      1025
   macro avg       0.94      0.94      0.94      1025
weighted avg       0.94      0.94      0.94      1025


 > Model: K-Neighbors Classifier
   - Accuracy : 0.8810
   - F1 Macro : 0.8793 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

         0.0       0.96      0.79      0.87       497
         1.0       0.83      0.97      0.89       528

    accuracy                           0.88      1025
   macro avg       0.89      0.88      0.88      1025
weighted avg       0.89      0.88      0.88      1025


 > Model: SVC
   - Accuracy : 0.9259
   - F1 Macro : 0.9255 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

         0.0       0.96      0.89      0.92       497
         1.0       0.90      0.96      0.93       528

    accuracy                           0.93      1025
   macro avg       0.93      0.92      0.93      1025
weighted avg       0.93      0.93      0.93      1025


 > Model: Random Forest Classifier
   - Accuracy : 0.9366
   - F1 Macro : 0.9363 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

         0.0       0.97      0.90      0.93       497
         1.0       0.91      0.97      0.94       528

    accuracy                           0.94      1025
   macro avg       0.94      0.94      0.94      1025
weighted avg       0.94      0.94      0.94      1025


 > Model: Gradient Boosting Classifier
   - Accuracy : 0.9346
   - F1 Macro : 0.9343 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

         0.0       0.97      0.90      0.93       497
         1.0       0.91      0.97      0.94       528

    accuracy                           0.93      1025
   macro avg       0.94      0.93      0.93      1025
weighted avg       0.94      0.93      0.93      1025


 > Model: MLP Classifier
   - Accuracy : 0.9288
   - F1 Macro : 0.9286 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

         0.0       0.95      0.91      0.92       497
         1.0       0.91      0.95      0.93       528

    accuracy                           0.93      1025
   macro avg       0.93      0.93      0.93      1025
weighted avg       0.93      0.93      0.93      1025


 > Model: Linear SVC
   - Accuracy : 0.9141
   - F1 Macro : 0.9136 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

         0.0       0.96      0.86      0.91       497
         1.0       0.88      0.97      0.92       528

    accuracy                           0.91      1025
   macro avg       0.92      0.91      0.91      1025
weighted avg       0.92      0.91      0.91      1025


 > Model: Extra Trees Classifier
   - Accuracy : 0.9463
   - F1 Macro : 0.9461 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

         0.0       0.99      0.90      0.94       497
         1.0       0.91      0.99      0.95       528

    accuracy                           0.95      1025
   macro avg       0.95      0.95      0.95      1025
weighted avg       0.95      0.95      0.95      1025


==================================================
 BEST MODEL : Extra Trees Classifier
 Score      : 0.9461
 Params     : {'n_estimators': 150, 'max_depth': 30, 'min_samples_split': 5, 'n_jobs': 1}
==================================================