[load dataset] Loading Dense dataset: data_J
[fit] multiclass_classification task detected.

    Dataset Target Analysis (8237 samples)
 Type: Multiclass Classification [IMBALANCED]
  -> Class 0  : 933    samples (11.33%)
  -> Class 1  : 1433   samples (17.40%)
  -> Class 2  : 1927   samples (23.39%)
  -> Class 3  : 1515   samples (18.39%)
  -> Class 4  : 979    samples (11.89%)
  -> Class 5  : 948    samples (11.51%)
  -> Class 6  : 502    samples (6.09%)


[fit] Dense features threshold exceeded (800 > 500).
[fit] Reducing to the top 500 features...

[fit] Candidate models loaded for task 'multiclass_classification':
   1. Logistic Regression
   2. Hist Gradient Boosting
   3. K-Neighbors Classifier
   4. Gaussian Naive Bayes
   5. Bernoulli Naive Bayes
   6. SVC
   7. Random Forest Classifier
   8. Gradient Boosting Classifier

 [filter models] Dynamic Model Filtering ---
 Dataset Info: 6589 rows, 500 cols, Sparse=False
 -> Models selected: 8 / 8

[CLUSTER] Optimizing: Logistic Regression...
/info/etu/m1/s2501728/miniconda3/envs/autoML_env/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:110: UserWarning: Features [156 178 214 241 323 397] are constant.
  warnings.warn("Features %s are constant." % constant_features_idx, UserWarning)
/info/etu/m1/s2501728/miniconda3/envs/autoML_env/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:111: RuntimeWarning: invalid value encountered in divide
  f = msb / msw
[CLUSTER] Success. Best params: {'C': 0.22975575486734093, 'solver': 'lbfgs', 'max_iter': 5000}
[fit] Retraining final model on full data...
[CLUSTER] Optimizing: Hist Gradient Boosting...
[CLUSTER] Success. Best params: {'learning_rate': 0.035723946528898286, 'max_iter': 654, 'max_depth': 20, 'l2_regularization': 0.8789585151970873}
[fit] Retraining final model on full data...
[CLUSTER] Optimizing: K-Neighbors Classifier...
[CLUSTER] Success. Best params: {'n_neighbors': 8, 'weights': 'distance', 'p': 2, 'n_jobs': 1}
[fit] Retraining final model on full data...
[CLUSTER] Optimizing: Gaussian Naive Bayes...
[CLUSTER] Success. Best params: {'var_smoothing': 2.2587300013966007e-09}
[fit] Retraining final model on full data...
[CLUSTER] Optimizing: Bernoulli Naive Bayes...
[CLUSTER] Success. Best params: {'alpha': 0.06897252159978998, 'binarize': 0.21872101324232676}
[fit] Retraining final model on full data...
[CLUSTER] Optimizing: SVC...
[CLUSTER] Success. Best params: {'C': 309.39352266770265, 'kernel': 'sigmoid', 'gamma': 'auto', 'probability': True, 'max_iter': 10000}
[fit] Retraining final model on full data...
/info/etu/m1/s2501728/miniconda3/envs/autoML_env/lib/python3.12/site-packages/sklearn/svm/_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.
  warnings.warn(
[CLUSTER] Optimizing: Random Forest Classifier...
[CLUSTER] Success. Best params: {'n_estimators': 209, 'max_depth': 10, 'min_samples_split': 6, 'min_samples_leaf': 3, 'class_weight': 'balanced', 'n_jobs': 1}
[fit] Retraining final model on full data...
[CLUSTER] Optimizing: Gradient Boosting Classifier...
[CLUSTER] Success. Best params: {'n_estimators': 140, 'learning_rate': 0.05921884559882027, 'max_depth': 7, 'subsample': 0.8943776231585305}
[fit] Retraining final model on full data...

[eval] --- Detailed Results on Test Set (1648 samples) ---

 > Model: Logistic Regression
   - Accuracy : 0.7093
   - F1 Macro : 0.6861 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

           0       0.47      0.41      0.43       184
           1       0.57      0.58      0.58       289
           2       0.77      0.84      0.81       423
           3       0.92      0.94      0.93       301
           4       0.53      0.50      0.51       183
           5       0.70      0.69      0.70       164
           6       0.93      0.78      0.85       104

    accuracy                           0.71      1648
   macro avg       0.70      0.68      0.69      1648
weighted avg       0.71      0.71      0.71      1648


 > Model: Hist Gradient Boosting
   - Accuracy : 0.7136
   - F1 Macro : 0.6837 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

           0       0.49      0.42      0.45       184
           1       0.59      0.64      0.61       289
           2       0.80      0.85      0.82       423
           3       0.90      0.92      0.91       301
           4       0.54      0.48      0.51       183
           5       0.65      0.71      0.68       164
           6       0.91      0.71      0.80       104

    accuracy                           0.71      1648
   macro avg       0.70      0.68      0.68      1648
weighted avg       0.71      0.71      0.71      1648


 > Model: K-Neighbors Classifier
   - Accuracy : 0.6675
   - F1 Macro : 0.6397 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

           0       0.38      0.28      0.32       184
           1       0.55      0.49      0.52       289
           2       0.71      0.84      0.77       423
           3       0.92      0.93      0.92       301
           4       0.42      0.45      0.44       183
           5       0.66      0.66      0.66       164
           6       0.92      0.79      0.85       104

    accuracy                           0.67      1648
   macro avg       0.65      0.63      0.64      1648
weighted avg       0.66      0.67      0.66      1648


 > Model: Gaussian Naive Bayes
   - Accuracy : 0.5000
   - F1 Macro : 0.5019 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

           0       0.34      0.29      0.31       184
           1       0.42      0.26      0.32       289
           2       0.84      0.28      0.42       423
           3       0.77      0.90      0.83       301
           4       0.26      0.72      0.38       183
           5       0.52      0.56      0.54       164
           6       0.64      0.83      0.72       104

    accuracy                           0.50      1648
   macro avg       0.54      0.55      0.50      1648
weighted avg       0.59      0.50      0.49      1648


 > Model: Bernoulli Naive Bayes
   - Accuracy : 0.6001
   - F1 Macro : 0.5707 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

           0       0.38      0.27      0.31       184
           1       0.42      0.53      0.47       289
           2       0.64      0.68      0.66       423
           3       0.92      0.94      0.93       301
           4       0.37      0.30      0.33       183
           5       0.55      0.51      0.53       164
           6       0.78      0.75      0.76       104

    accuracy                           0.60      1648
   macro avg       0.58      0.57      0.57      1648
weighted avg       0.59      0.60      0.59      1648


 > Model: SVC
   - Accuracy : 0.5983
   - F1 Macro : 0.5796 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

           0       0.27      0.35      0.31       184
           1       0.44      0.53      0.48       289
           2       0.71      0.71      0.71       423
           3       0.91      0.84      0.88       301
           4       0.39      0.32      0.35       183
           5       0.67      0.55      0.61       164
           6       0.89      0.62      0.73       104

    accuracy                           0.60      1648
   macro avg       0.61      0.56      0.58      1648
weighted avg       0.62      0.60      0.61      1648


 > Model: Random Forest Classifier
   - Accuracy : 0.5225
   - F1 Macro : 0.5077 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

           0       0.44      0.11      0.17       184
           1       0.29      0.78      0.42       289
           2       0.83      0.38      0.52       423
           3       0.80      0.87      0.83       301
           4       0.40      0.20      0.26       183
           5       0.63      0.51      0.56       164
           6       0.87      0.69      0.77       104

    accuracy                           0.52      1648
   macro avg       0.61      0.51      0.51      1648
weighted avg       0.62      0.52      0.51      1648


 > Model: Gradient Boosting Classifier
   - Accuracy : 0.7172
   - F1 Macro : 0.6967 (Balanced metric)

[Classification Report]
              precision    recall  f1-score   support

           0       0.58      0.39      0.47       184
           1       0.52      0.67      0.58       289
           2       0.78      0.84      0.81       423
           3       0.91      0.94      0.92       301
           4       0.59      0.49      0.53       183
           5       0.72      0.63      0.67       164
           6       0.97      0.82      0.89       104

    accuracy                           0.72      1648
   macro avg       0.72      0.68      0.70      1648
weighted avg       0.72      0.72      0.71      1648


==================================================
 BEST MODEL : Gradient Boosting Classifier
 Score      : 0.6967
 Params     : {'n_estimators': 140, 'learning_rate': 0.05921884559882027, 'max_depth': 7, 'subsample': 0.8943776231585305}
==================================================