-> Tache de type binary_classification detecté.

--- Analyse de la distribution du dataset complet (3140 lignes) ---
 -> Classe 0.0 : 1561 exemples (49.71%)
 -> Classe 1.0 : 1579 exemples (50.29%)
-> Prétraitement mode DENSE

-> Choix des models pertinant : 

1 - Logistic Regression
2 - Hist Gradient Boosting
3 - K-Neighbors Classifier
4 - Gaussian Naive Bayes
5 - SVC
6 - Random Forest Classifier
7 - Bernoulli Naive Bayes
8 - Gradient Boosting Classifier
9 - MLP Classifier

 Optimisation du modèle : Logistic Regression
Fitting 3 folds for each of 5 candidates, totalling 15 fits
   => Meilleurs paramètres trouvés : {'C': 0.01, 'max_iter': 2000, 'solver': 'lbfgs'}

 Optimisation du modèle : Hist Gradient Boosting
Fitting 3 folds for each of 8 candidates, totalling 24 fits
   => Meilleurs paramètres trouvés : {'learning_rate': 0.1, 'max_depth': 10, 'max_iter': 200, 'min_samples_leaf': 20}

 Optimisation du modèle : K-Neighbors Classifier
Fitting 3 folds for each of 8 candidates, totalling 24 fits
   => Meilleurs paramètres trouvés : {'n_jobs': 1, 'n_neighbors': 15, 'weights': 'distance'}

 Optimisation du modèle : Gaussian Naive Bayes
Fitting 3 folds for each of 4 candidates, totalling 12 fits
   => Meilleurs paramètres trouvés : {'var_smoothing': 1e-09}

 Optimisation du modèle : SVC
Fitting 3 folds for each of 16 candidates, totalling 48 fits
   => Meilleurs paramètres trouvés : {'C': 10, 'gamma': 'auto', 'kernel': 'rbf', 'max_iter': 5000}

 Optimisation du modèle : Random Forest Classifier
Fitting 3 folds for each of 8 candidates, totalling 24 fits
   => Meilleurs paramètres trouvés : {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200, 'n_jobs': 1}

 Optimisation du modèle : Bernoulli Naive Bayes
Fitting 3 folds for each of 6 candidates, totalling 18 fits
   => Meilleurs paramètres trouvés : {'alpha': 0.1, 'binarize': 0.0}

 Optimisation du modèle : Gradient Boosting Classifier
Fitting 3 folds for each of 12 candidates, totalling 36 fits
   => Meilleurs paramètres trouvés : {'learning_rate': 0.05, 'max_depth': 5, 'n_estimators': 100}

 Optimisation du modèle : MLP Classifier
Fitting 3 folds for each of 12 candidates, totalling 36 fits
   => Meilleurs paramètres trouvés : {'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': [100], 'max_iter': 5000}

 -> Résultats détaillés : 

--- Rapport pour : Logistic Regression ---
Accuracy: 0.5924
F1-Score (Weighted): 0.5924 (Biaisé vers la majorité)
F1-Score (Macro)   : 0.5919 (Équitable)
              precision    recall  f1-score   support

         0.0       0.58      0.58      0.58       302
         1.0       0.61      0.60      0.61       326

    accuracy                           0.59       628
   macro avg       0.59      0.59      0.59       628
weighted avg       0.59      0.59      0.59       628

--- Rapport pour : Hist Gradient Boosting ---
Accuracy: 0.8503
F1-Score (Weighted): 0.8504 (Biaisé vers la majorité)
F1-Score (Macro)   : 0.8502 (Équitable)
              precision    recall  f1-score   support

         0.0       0.84      0.85      0.85       302
         1.0       0.86      0.85      0.85       326

    accuracy                           0.85       628
   macro avg       0.85      0.85      0.85       628
weighted avg       0.85      0.85      0.85       628

--- Rapport pour : K-Neighbors Classifier ---
Accuracy: 0.6242
F1-Score (Weighted): 0.6238 (Biaisé vers la majorité)
F1-Score (Macro)   : 0.6241 (Équitable)
              precision    recall  f1-score   support

         0.0       0.60      0.67      0.63       302
         1.0       0.66      0.58      0.62       326

    accuracy                           0.62       628
   macro avg       0.63      0.63      0.62       628
weighted avg       0.63      0.62      0.62       628

--- Rapport pour : Gaussian Naive Bayes ---
Accuracy: 0.6083
F1-Score (Weighted): 0.6084 (Biaisé vers la majorité)
F1-Score (Macro)   : 0.6081 (Équitable)
              precision    recall  f1-score   support

         0.0       0.59      0.61      0.60       302
         1.0       0.63      0.60      0.62       326

    accuracy                           0.61       628
   macro avg       0.61      0.61      0.61       628
weighted avg       0.61      0.61      0.61       628

--- Rapport pour : SVC ---
Accuracy: 0.6242
F1-Score (Weighted): 0.6242 (Biaisé vers la majorité)
F1-Score (Macro)   : 0.6236 (Équitable)
              precision    recall  f1-score   support

         0.0       0.61      0.61      0.61       302
         1.0       0.64      0.64      0.64       326

    accuracy                           0.62       628
   macro avg       0.62      0.62      0.62       628
weighted avg       0.62      0.62      0.62       628

--- Rapport pour : Random Forest Classifier ---
Accuracy: 0.7803
F1-Score (Weighted): 0.7803 (Biaisé vers la majorité)
F1-Score (Macro)   : 0.7802 (Équitable)
              precision    recall  f1-score   support

         0.0       0.76      0.80      0.78       302
         1.0       0.81      0.76      0.78       326

    accuracy                           0.78       628
   macro avg       0.78      0.78      0.78       628
weighted avg       0.78      0.78      0.78       628

--- Rapport pour : Bernoulli Naive Bayes ---
Accuracy: 0.6083
F1-Score (Weighted): 0.6082 (Biaisé vers la majorité)
F1-Score (Macro)   : 0.6076 (Équitable)
              precision    recall  f1-score   support

         0.0       0.59      0.59      0.59       302
         1.0       0.62      0.63      0.62       326

    accuracy                           0.61       628
   macro avg       0.61      0.61      0.61       628
weighted avg       0.61      0.61      0.61       628

--- Rapport pour : Gradient Boosting Classifier ---
Accuracy: 0.8280
F1-Score (Weighted): 0.8280 (Biaisé vers la majorité)
F1-Score (Macro)   : 0.8277 (Équitable)
              precision    recall  f1-score   support

         0.0       0.83      0.81      0.82       302
         1.0       0.83      0.84      0.84       326

    accuracy                           0.83       628
   macro avg       0.83      0.83      0.83       628
weighted avg       0.83      0.83      0.83       628

--- Rapport pour : MLP Classifier ---
Accuracy: 0.5812
F1-Score (Weighted): 0.5809 (Biaisé vers la majorité)
F1-Score (Macro)   : 0.5801 (Équitable)
              precision    recall  f1-score   support

         0.0       0.57      0.55      0.56       302
         1.0       0.59      0.61      0.60       326

    accuracy                           0.58       628
   macro avg       0.58      0.58      0.58       628
weighted avg       0.58      0.58      0.58       628


================================================
 MEILLEUR MODÈLE : Hist Gradient Boosting
 Score retenu    : 0.8502
 Hyperparamètres : {'learning_rate': 0.1, 'max_depth': 10, 'max_iter': 200, 'min_samples_leaf': 20}
================================================