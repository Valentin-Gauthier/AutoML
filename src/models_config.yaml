# ==========================================================
# Grilles d'hyperparamètres pour les modèles de Régression
# ==========================================================

Ridge:
  # alpha: Force de la régularisation (L2). Plus alpha est élevé, plus la régularisation est forte.
  alpha: [0.1, 1.0, 10.0]

K-Neighbors Regressor:
  # n_neighbors: Nombre de voisins 'k' à considérer.
  n_neighbors: [3, 5, 9]
  # weights: 'uniform' (tous les voisins ont le même poids), 'distance' (les voisins proches ont plus d'impact).
  weights: ['uniform', 'distance']

SVR:
  # C: Paramètre de régularisation. Inverse de la force de régularisation (plus C est grand, moins on régularise).
  C: [0.1, 1, 10]
  # kernel: Type de noyau pour gérer la non-linéarité. 'rbf' est le plus courant.
  kernel: ['linear', 'rbf']

Random Forest Regressor:
  # n_estimators: Nombre d'arbres dans la forêt.
  n_estimators: [100, 200]
  # max_depth: Profondeur maximale de chaque arbre. 'null' signifie pas de limite.
  max_depth: [null, 10]

Gradient Boosting Regressor:
  # n_estimators: Nombre d'étapes de boosting (nombre d'arbres).
  n_estimators: [100, 200]
  # learning_rate: Taux d'apprentissage (réduit la contribution de chaque arbre).
  learning_rate: [0.1]
  # max_depth: Profondeur de chaque arbre. Généralement faible pour le boosting.
  max_depth: [3, 5]

# ===================================================================
# Grilles d'hyperparamètres pour les modèles de Classification
# (Binaire et Multi-classe)
# ===================================================================

Logistic Regression:
  # C: Inverse de la force de régularisation.
  C: [0.1, 1, 10]
  # solver: Algorithme à utiliser pour l'optimisation. 'liblinear' est bon pour les petits datasets.
  solver: ['liblinear']

K-Neighbors Classifier:
  # n_neighbors: Nombre de voisins 'k' à considérer.
  n_neighbors: [3, 5, 9]
  # weights: 'uniform' (vote à la majorité), 'distance' (les voisins proches ont plus de poids).
  weights: ['uniform', 'distance']

SVC:
  # C: Paramètre de régularisation.
  C: [0.1, 1, 10]
  # kernel: Type de noyau.
  kernel: ['linear', 'rbf']

Random Forest Classifier:
  # n_estimators: Nombre d'arbres dans la forêt.
  n_estimators: [100, 200]
  # max_depth: Profondeur maximale de chaque arbre.
  max_depth: [null, 10]

Gradient Boosting Classifier:
  # n_estimators: Nombre d'étapes de boosting.
  n_estimators: [100, 200]
  # learning_rate: Taux d'apprentissage.
  learning_rate: [0.1]
  # max_depth: Profondeur de chaque arbre.
  max_depth: [3, 5]

# ===================================================================
# Grilles d'hyperparamètres pour les modèles Multi-label
# ATTENTION: Le préfixe 'estimator__' est obligatoire !
# ===================================================================

RF Multi-label:
  # estimator__n_estimators: Nombre d'arbres (passé au RandomForest *dans* le MultiOutput).
  estimator__n_estimators: [100]
  # estimator__max_depth: Profondeur maximale.
  estimator__max_depth: [null, 10]

KN Multi-label:
  # estimator__n_neighbors: Nombre de voisins.
  estimator__n_neighbors: [3, 5, 9]

GB Multi-label:
  # estimator__n_estimators: Nombre d'arbres.
  estimator__n_estimators: [100, 200]
  # estimator__max_depth: Profondeur maximale.
  estimator__max_depth: [3, 5]