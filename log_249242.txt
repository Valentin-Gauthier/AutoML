############################################### Traitement du dataset : data_B #############################################
[load dataset] Loading Dense dataset: data_B
[fit] regression task detected.

    Dataset Target Analysis (5000 samples)
 Type: Regression
  - Min:    14999.0000
  - Max:    500001.0000
  - Mean:   207568.8056
  - Median: 179500.0000
  - StdDev: 115383.4602



[fit] Candidate models loaded for task 'regression':
   1. Linear Regression
   2. Ridge
   3. K-Neighbors Regressor
   4. SVR
   5. Random Forest Regressor
   6. Gradient Boosting Regressor
   7. MLP Regressor
   8. Hist Gradient Boosting
   9. ElasticNet
   10. Linear SVR
   11. Extra Trees Regressor

 [filter models] Dynamic Model Filtering ---
 Dataset Info: 4000 rows, 16 cols, Sparse=False
 -> Models selected: 11 / 11

[CLUSTER] Optimizing: Linear Regression...
[CLUSTER] Success (23.9s). Best params: {'fit_intercept': True}
[fit] Retraining final model on full data...
[fit] Final training done in 0.1s.
[CLUSTER] Optimizing: Ridge...
[CLUSTER] Success (22.2s). Best params: {'alpha': 2.989675533844218}
[fit] Retraining final model on full data...
[fit] Final training done in 0.0s.
[CLUSTER] Optimizing: K-Neighbors Regressor...
[CLUSTER] Success (27.0s). Best params: {'n_neighbors': 15, 'weights': 'distance', 'p': 1, 'n_jobs': 1}
[fit] Retraining final model on full data...
[fit] Final training done in 0.0s.
[CLUSTER] Optimizing: SVR...
[CLUSTER] Success (38.1s). Best params: {'C': 361.55866783594314, 'kernel': 'linear', 'gamma': 'scale', 'epsilon': 0.3739185533632968, 'max_iter': 5000}
[fit] Retraining final model on full data...
[fit] Final training done in 1.4s.
[CLUSTER] Optimizing: Random Forest Regressor...
[CLUSTER] Success (200.3s). Best params: {'n_estimators': 199, 'max_depth': None, 'min_samples_split': 6, 'min_samples_leaf': 3, 'n_jobs': 1}
[fit] Retraining final model on full data...
[fit] Final training done in 1.8s.
[CLUSTER] Optimizing: Gradient Boosting Regressor...
[CLUSTER] Success (91.7s). Best params: {'n_estimators': 177, 'learning_rate': 0.05098192844203401, 'max_depth': 4, 'subsample': 0.9509659376461443, 'n_iter_no_change': 10, 'validation_fraction': 0.1}
[fit] Retraining final model on full data...
[fit] Final training done in 8.6s.
[CLUSTER] Optimizing: MLP Regressor...
[CLUSTER] Success (65.2s). Best params: {'regressor__hidden_layer_sizes': [100, 50], 'regressor__activation': 'tanh', 'regressor__alpha': 0.00039433769485148004, 'regressor__learning_rate_init': 0.001899518618759317, 'regressor__max_iter': 500, 'regressor__early_stopping': True, 'regressor__n_iter_no_change': 10}
[fit] Retraining final model on full data...
[fit] Final training done in 4.7s.
[CLUSTER] Optimizing: Hist Gradient Boosting...
[CLUSTER] Success (81.8s). Best params: {'learning_rate': 0.019334501862478697, 'max_iter': 405, 'max_depth': None, 'l2_regularization': 0.969122548409724, 'early_stopping': True, 'n_iter_no_change': 10}
[fit] Retraining final model on full data...
[fit] Final training done in 3.5s.
[CLUSTER] Optimizing: ElasticNet...
[CLUSTER] Success (21.1s). Best params: {'alpha': 0.018706845166681633, 'l1_ratio': 0.9}
[fit] Retraining final model on full data...
[fit] Final training done in 0.1s.
[CLUSTER] Optimizing: Linear SVR...
[CLUSTER] Success (22.1s). Best params: {'C': 81.29077299116567, 'epsilon': 0.1, 'max_iter': 2000}
[fit] Retraining final model on full data...
[fit] Final training done in 0.0s.
[CLUSTER] Optimizing: Extra Trees Regressor...
[CLUSTER] Success (67.4s). Best params: {'n_estimators': 110, 'max_depth': None, 'min_samples_split': 2, 'n_jobs': 1}
[fit] Retraining final model on full data...
[fit] Final training done in 0.5s.

[eval] --- Detailed Results on Test Set (1000 samples) ---

 > Model: Linear Regression
   - MSE: 4749054027.8971
   - R2 : 0.6342

 > Model: Ridge
   - MSE: 4752893407.8170
   - R2 : 0.6339

 > Model: K-Neighbors Regressor
   - MSE: 6897900769.4442
   - R2 : 0.4687

 > Model: SVR
   - MSE: 5616922596.3444
   - R2 : 0.5674

 > Model: Random Forest Regressor
   - MSE: 3469496930.3420
   - R2 : 0.7328

 > Model: Gradient Boosting Regressor
   - MSE: 2964744009.2878
   - R2 : 0.7716

 > Model: MLP Regressor
   - MSE: 3753916113.7170
   - R2 : 0.7109

 > Model: Hist Gradient Boosting
   - MSE: 2786108083.8136
   - R2 : 0.7854

 > Model: ElasticNet
   - MSE: 4759117719.8330
   - R2 : 0.6334

 > Model: Linear SVR
   - MSE: 10571948990.0683
   - R2 : 0.1857

 > Model: Extra Trees Regressor
   - MSE: 3761605629.7910
   - R2 : 0.7103

==================================================
 BEST MODEL : Hist Gradient Boosting
 Score      : 0.7854
 Params     : {'learning_rate': 0.019334501862478697, 'max_iter': 405, 'max_depth': None, 'l2_regularization': 0.969122548409724, 'early_stopping': True, 'n_iter_no_change': 10}
==================================================

############################################### Traitement du dataset : data_C #############################################
[load dataset] Loading Dense dataset: data_C
[fit] multiclass_classification task detected.

    Dataset Target Analysis (15000 samples)
 Type: Multiclass Classification [Balanced]
  -> Class 0  : 1493   samples (9.95%)
  -> Class 1  : 1786   samples (11.91%)
  -> Class 2  : 1506   samples (10.04%)
  -> Class 3  : 1461   samples (9.74%)
  -> Class 4  : 1422   samples (9.48%)
  -> Class 5  : 1344   samples (8.96%)
  -> Class 6  : 1442   samples (9.61%)
  -> Class 7  : 1604   samples (10.69%)
  -> Class 8  : 1472   samples (9.81%)
  -> Class 9  : 1470   samples (9.80%)


[fit] Features threshold exceeded (1568 > 800).
[fit] Reducing to the top 800 features...
[fit] Warning: Only kept 51.02% of the features !
[fit] Reduction done. New shape: (12000, 800)

[fit] Candidate models loaded for task 'multiclass_classification':
   1. Logistic Regression
   2. Hist Gradient Boosting
   3. K-Neighbors Classifier
   4. Gaussian Naive Bayes
   5. Bernoulli Naive Bayes
   6. SVC
   7. Random Forest Classifier
   8. Gradient Boosting Classifier
   9. Linear SVC
   10. Extra Trees Classifier

 [filter models] Dynamic Model Filtering ---
 Dataset Info: 12000 rows, 800 cols, Sparse=False
 [EXCLUDED] K-Neighbors Classifier............. : Ineffective in high dimensions (800 cols)
 [EXCLUDED] Gaussian Naive Bayes............... : Incompatible with negative values (StandardScaler)
 [EXCLUDED] Bernoulli Naive Bayes.............. : Incompatible with negative values (StandardScaler)
 [EXCLUDED] SVC................................ : Too slow for 12000 rows (Cubic Complexity)
 -> Models selected: 6 / 10

[CLUSTER] Optimizing: Logistic Regression...
